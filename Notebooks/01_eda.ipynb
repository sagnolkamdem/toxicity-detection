{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory Datat Analysis",
   "id": "b0fb93ef94b770fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:10:26.051034Z",
     "start_time": "2025-12-29T14:10:25.248330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('../Data/train.csv')\n",
    "data.head()\n"
   ],
   "id": "e9212eab77350437",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "24f43b339ef80755"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:10:32.407040Z",
     "start_time": "2025-12-29T14:10:32.393856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"total samples: {data.shape[0]}\")\n",
    "print(\"*\"*50)\n",
    "print(f\"total features: {data.shape[1]}\")"
   ],
   "id": "896c291b4698cddf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 159571\n",
      "**************************************************\n",
      "total features: 8\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:10:34.846294Z",
     "start_time": "2025-12-29T14:10:34.687067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(data.info())\n",
    "print(data.describe())"
   ],
   "id": "5f09fd1e9ccf55c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             159571 non-null  object\n",
      " 1   comment_text   159571 non-null  object\n",
      " 2   toxic          159571 non-null  int64 \n",
      " 3   severe_toxic   159571 non-null  int64 \n",
      " 4   obscene        159571 non-null  int64 \n",
      " 5   threat         159571 non-null  int64 \n",
      " 6   insult         159571 non-null  int64 \n",
      " 7   identity_hate  159571 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n",
      "None\n",
      "               toxic   severe_toxic        obscene         threat  \\\n",
      "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
      "mean        0.095844       0.009996       0.052948       0.002996   \n",
      "std         0.294379       0.099477       0.223931       0.054650   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "              insult  identity_hate  \n",
      "count  159571.000000  159571.000000  \n",
      "mean        0.049364       0.008805  \n",
      "std         0.216627       0.093420  \n",
      "min         0.000000       0.000000  \n",
      "25%         0.000000       0.000000  \n",
      "50%         0.000000       0.000000  \n",
      "75%         0.000000       0.000000  \n",
      "max         1.000000       1.000000  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T14:10:38.304941Z",
     "start_time": "2025-12-29T14:10:37.730959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "LLM_SAMPLE_SIZE = 200\n",
    "\n",
    "# STEP 1: LOAD & CONSOLIDATE LABELS\n",
    "df = data\n",
    "\n",
    "toxicity_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Create a single binary target\n",
    "df['final_label'] = df[toxicity_cols].max(axis=1)\n",
    "\n",
    "print(f\"Data loaded. Total rows: {len(df)}\")\n",
    "print(f\"Toxic samples: {df['final_label'].sum()} | Non-Toxic samples: {len(df) - df['final_label'].sum()}\")\n",
    "\n",
    "\n",
    "# STEP 2: SPLIT & CREATE GOLDEN SAMPLE (80/20)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Now, extract the small \"Golden Sample\" specifically for the LLM\n",
    "# We use .copy() to avoid SettingWithCopy warnings\n",
    "llm_sample = test_df.sample(n=LLM_SAMPLE_SIZE, random_state=SEED).copy()\n",
    "\n",
    "print(f\"LLM Sample of {len(llm_sample)} rows (from Test set).\")\n",
    "\n",
    "# STEP 3: MINIMAL CLEANING\n",
    "llm_sample['cleaned_text'] = llm_sample['comment_text'].str.replace('\\n', ' ', regex=False)\n",
    "\n",
    "# STEP 4: PROMPT ENGINEERING\n",
    "prompt_template = \"\"\"You are the best content moderator in the history.\n",
    "                     If you fail in your job, your company will shutdown.\n",
    "                     Classify the following text as 'Toxic' or 'Non-Toxic'.\n",
    "                     Reply with ONLY one word.\n",
    "\n",
    "                     Text: \"{}\"\n",
    "                     Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Apply the template to every row\n",
    "llm_sample['llm_prompt'] = llm_sample['cleaned_text'].apply(lambda x: prompt_template.format(x))\n",
    "\n",
    "\n",
    "# STEP 5: SAVE ARTIFACTS\n",
    "output_cols = ['id', 'final_label', 'llm_prompt']\n",
    "llm_sample[output_cols].to_csv('../Data/llm/llm_baseline_inputs.csv', index=False)\n",
    "llm_sample['id'].to_csv('../Data/RoBERTa/golden_sample_ids.csv', index=False)\n",
    "\n",
    "print(\"\\nProcessing complete!\")\n",
    "print(\"1. 'llm_baseline_inputs.csv' -> Feed this to your LLM.\")\n",
    "print(\"2. 'golden_sample_ids.csv' -> Use this to filter RoBERTa predictions later.\")"
   ],
   "id": "b0188239f82c011e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Total rows: 159571\n",
      "Toxic samples: 16225 | Non-Toxic samples: 143346\n",
      "LLM Sample of 200 rows (from Test set).\n",
      "\n",
      "Processing complete!\n",
      "1. 'llm_baseline_inputs.csv' -> Feed this to your LLM.\n",
      "2. 'golden_sample_ids.csv' -> Use this to filter RoBERTa predictions later.\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
